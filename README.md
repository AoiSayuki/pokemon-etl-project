# PokÃ©mon Data Analytics Pipeline (ETL)
## ğŸ“‹ Project Overview
This project demonstrates a full ETL (Extract, Transform, Load) pipeline that processes data for all 1,025 PokÃ©mon across 9 generations. The goal was to analyze PokÃ©mon species as "assets," comparing performance metrics, type efficiencies, and generational trends.

## ğŸ› ï¸ Tech Stack
- Language: Python 3.x
- Libraries: Pandas (Data Manipulation), SQLAlchemy (Database Connection)
- Database: SQLite
- Visualization: Power BI
- Data Source: PokeAPI (Raw CSV exports)

## âš™ï¸ The ETL Process
1. Extract
- Raw data was sourced in CSV format, containing detailed base stats, dimensions, and classifications for every PokÃ©mon, along with a separate dataset for elemental type relations (Strengths/Weaknesses).

2. Transform
- Using Pandas, the data underwent rigorous cleaning to ensure it was "dashboard-ready":
  - Standardization: Converted height and weight to metric units (meters/kg).
  - Normalization: Lowercased all string values for consistency.
  - Feature Engineering: Calculated total_stats.
  - Mapped generation IDs to readable labels (e.g., "Gen 1").
  - Normalized capture_rate and gender_rate to decimal scales.
  - Data Integrity: Handled missing values (NaN) in dual-type PokÃ©mon to ensure accurate SQL joins.
  
3. Load
- The cleaned data was programmatically loaded into a SQLite database (pokemon_db.db) using SQLAlchemy. This ensures the data is structured, indexed, and ready for relational queries or BI tool integration via ODBC.

## ğŸ“Š Dashboard Insights
- The final Power BI dashboard focuses on high-level distribution and comparative analysis rather than individual entries:
  - KPIs: Total Species, Average Base Stat Total (BST), Average Capture Rate.
  - Generational Analysis: A Line Chart comparing the number of PokÃ©mon added Gen 1 to Gen 9.
  - Stat Distribution: Bar Chart showing the spread of Total Stats across different Primary Types.

## ğŸ“ Project Structure
```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_pokemon_data.csv       # Original pokemon data
â”‚   â”œâ”€â”€ raw_type_data.csv          # Original type data
â”‚   â”œâ”€â”€ clean_pokemon_data.csv     # Transformed data
â”‚   â””â”€â”€ clean_type_data.csv        # Processed type relations
â”œâ”€â”€ db/
â”‚   â””â”€â”€ pokemon_db.db              # Final SQLite Database
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ extract_pokemon.py         # Pokemon collection script
â”‚   â”œâ”€â”€ extract_type_relations.py  # Type collection script
â”‚   â”œâ”€â”€ transform_script.py        # Pandas cleaning logic
â”‚   â””â”€â”€ load_script.py             # SQLAlchemy loading logic
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ pokemon_analytics.pbix     # Power BI Dashboard file
â””â”€â”€ README.md
```

## ğŸš€ How to Run
1. Clone the repository.
2. Install dependencies:
  - pip install pandas sqlalchemy.
3. Run the scripts:
  - Execute the transformation script to generate the clean CSVs.
  - Execute the load script to populate the SQLite database in the /db folder.
4. Connect to Power BI:
  - Open the .pbix file.
5. Update the ODBC DSN to point to your local pokemon_db.db file.


